{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1408,"status":"ok","timestamp":1725963956328,"user":{"displayName":"ritn B","userId":"17631196088925960099"},"user_tz":300},"id":"qod5JM1COQQw","outputId":"cdf66188-de2b-48d0-b120-ebd6549fa73d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4451,"status":"ok","timestamp":1725963960778,"user":{"displayName":"ritn B","userId":"17631196088925960099"},"user_tz":300},"id":"7-DayOc7NtmX"},"outputs":[],"source":["# # 필요한 라이브러리 설치\n","# !pip install tensorflow==2.15.0\n","# !pip install tensorflow-quantum==0.7.3\n","\n","# 라이브러리 임포트\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_quantum as tfq\n","import cirq\n","import sympy\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"executionInfo":{"elapsed":2362,"status":"ok","timestamp":1725963963139,"user":{"displayName":"ritn B","userId":"17631196088925960099"},"user_tz":300},"id":"UOvbBB1WYNsf","outputId":"dd20f441-4f10-4f65-cb2d-437a66b23c20"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Summary of the CSV DataFrame:\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"},"text/html":["\n","  \u003cdiv id=\"df-37c3034f-6eb9-4a84-8acb-b3cffce97f89\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eIPV4_SRC_ADDR\u003c/th\u003e\n","      \u003cth\u003eL4_SRC_PORT\u003c/th\u003e\n","      \u003cth\u003eIPV4_DST_ADDR\u003c/th\u003e\n","      \u003cth\u003eL4_DST_PORT\u003c/th\u003e\n","      \u003cth\u003ePROTOCOL\u003c/th\u003e\n","      \u003cth\u003eL7_PROTO\u003c/th\u003e\n","      \u003cth\u003eIN_BYTES\u003c/th\u003e\n","      \u003cth\u003eOUT_BYTES\u003c/th\u003e\n","      \u003cth\u003eIN_PKTS\u003c/th\u003e\n","      \u003cth\u003eOUT_PKTS\u003c/th\u003e\n","      \u003cth\u003eTCP_FLAGS\u003c/th\u003e\n","      \u003cth\u003eFLOW_DURATION_MILLISECONDS\u003c/th\u003e\n","      \u003cth\u003eLabel\u003c/th\u003e\n","      \u003cth\u003eAttack\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e149.171.126.0\u003c/td\u003e\n","      \u003ctd\u003e62073\u003c/td\u003e\n","      \u003ctd\u003e59.166.0.5\u003c/td\u003e\n","      \u003ctd\u003e56082\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e9672\u003c/td\u003e\n","      \u003ctd\u003e416\u003c/td\u003e\n","      \u003ctd\u003e11\u003c/td\u003e\n","      \u003ctd\u003e8\u003c/td\u003e\n","      \u003ctd\u003e25\u003c/td\u003e\n","      \u003ctd\u003e15\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e149.171.126.2\u003c/td\u003e\n","      \u003ctd\u003e32284\u003c/td\u003e\n","      \u003ctd\u003e59.166.0.5\u003c/td\u003e\n","      \u003ctd\u003e1526\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1776\u003c/td\u003e\n","      \u003ctd\u003e104\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e25\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e149.171.126.0\u003c/td\u003e\n","      \u003ctd\u003e21\u003c/td\u003e\n","      \u003ctd\u003e59.166.0.1\u003c/td\u003e\n","      \u003ctd\u003e21971\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e1842\u003c/td\u003e\n","      \u003ctd\u003e1236\u003c/td\u003e\n","      \u003ctd\u003e26\u003c/td\u003e\n","      \u003ctd\u003e22\u003c/td\u003e\n","      \u003ctd\u003e25\u003c/td\u003e\n","      \u003ctd\u003e1111\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e59.166.0.1\u003c/td\u003e\n","      \u003ctd\u003e23800\u003c/td\u003e\n","      \u003ctd\u003e149.171.126.0\u003c/td\u003e\n","      \u003ctd\u003e46893\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e528\u003c/td\u003e\n","      \u003ctd\u003e8824\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e12\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e124\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e59.166.0.5\u003c/td\u003e\n","      \u003ctd\u003e63062\u003c/td\u003e\n","      \u003ctd\u003e149.171.126.2\u003c/td\u003e\n","      \u003ctd\u003e21\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e1786\u003c/td\u003e\n","      \u003ctd\u003e2340\u003c/td\u003e\n","      \u003ctd\u003e32\u003c/td\u003e\n","      \u003ctd\u003e34\u003c/td\u003e\n","      \u003ctd\u003e25\u003c/td\u003e\n","      \u003ctd\u003e1459\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1623113\u003c/th\u003e\n","      \u003ctd\u003e59.166.0.2\u003c/td\u003e\n","      \u003ctd\u003e1640\u003c/td\u003e\n","      \u003ctd\u003e149.171.126.8\u003c/td\u003e\n","      \u003ctd\u003e53\u003c/td\u003e\n","      \u003ctd\u003e17\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e130\u003c/td\u003e\n","      \u003ctd\u003e162\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1623114\u003c/th\u003e\n","      \u003ctd\u003e59.166.0.2\u003c/td\u003e\n","      \u003ctd\u003e3610\u003c/td\u003e\n","      \u003ctd\u003e149.171.126.6\u003c/td\u003e\n","      \u003ctd\u003e21\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e2044\u003c/td\u003e\n","      \u003ctd\u003e2404\u003c/td\u003e\n","      \u003ctd\u003e36\u003c/td\u003e\n","      \u003ctd\u003e34\u003c/td\u003e\n","      \u003ctd\u003e26\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1623115\u003c/th\u003e\n","      \u003ctd\u003e59.166.0.2\u003c/td\u003e\n","      \u003ctd\u003e4667\u003c/td\u003e\n","      \u003ctd\u003e149.171.126.6\u003c/td\u003e\n","      \u003ctd\u003e40725\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e320\u003c/td\u003e\n","      \u003ctd\u003e1918\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e8\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1623116\u003c/th\u003e\n","      \u003ctd\u003e59.166.0.2\u003c/td\u003e\n","      \u003ctd\u003e5641\u003c/td\u003e\n","      \u003ctd\u003e149.171.126.6\u003c/td\u003e\n","      \u003ctd\u003e56243\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e528\u003c/td\u003e\n","      \u003ctd\u003e8824\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e12\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1623117\u003c/th\u003e\n","      \u003ctd\u003e59.166.0.1\u003c/td\u003e\n","      \u003ctd\u003e1245\u003c/td\u003e\n","      \u003ctd\u003e149.171.126.6\u003c/td\u003e\n","      \u003ctd\u003e55094\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e216\u003c/td\u003e\n","      \u003ctd\u003e112\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e18\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBenign\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e1623118 rows × 14 columns\u003c/p\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37c3034f-6eb9-4a84-8acb-b3cffce97f89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-37c3034f-6eb9-4a84-8acb-b3cffce97f89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-37c3034f-6eb9-4a84-8acb-b3cffce97f89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","\u003cdiv id=\"df-9181e00e-e656-4a11-9db2-57a772a290cf\"\u003e\n","  \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-9181e00e-e656-4a11-9db2-57a772a290cf')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","  \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","  \u003cscript\u003e\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() =\u003e {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9181e00e-e656-4a11-9db2-57a772a290cf button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  \u003c/script\u003e\n","\u003c/div\u003e\n","\n","  \u003cdiv id=\"id_8b913f38-d924-4369-bf88-e82cb080464a\"\u003e\n","    \u003cstyle\u003e\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    \u003c/style\u003e\n","    \u003cbutton class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","    \u003cscript\u003e\n","      (() =\u003e {\n","      const buttonEl =\n","        document.querySelector('#id_8b913f38-d924-4369-bf88-e82cb080464a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () =\u003e {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["         IPV4_SRC_ADDR  L4_SRC_PORT  IPV4_DST_ADDR  L4_DST_PORT  PROTOCOL  \\\n","0        149.171.126.0        62073     59.166.0.5        56082         6   \n","1        149.171.126.2        32284     59.166.0.5         1526         6   \n","2        149.171.126.0           21     59.166.0.1        21971         6   \n","3           59.166.0.1        23800  149.171.126.0        46893         6   \n","4           59.166.0.5        63062  149.171.126.2           21         6   \n","...                ...          ...            ...          ...       ...   \n","1623113     59.166.0.2         1640  149.171.126.8           53        17   \n","1623114     59.166.0.2         3610  149.171.126.6           21         6   \n","1623115     59.166.0.2         4667  149.171.126.6        40725         6   \n","1623116     59.166.0.2         5641  149.171.126.6        56243         6   \n","1623117     59.166.0.1         1245  149.171.126.6        55094         6   \n","\n","         L7_PROTO  IN_BYTES  OUT_BYTES  IN_PKTS  OUT_PKTS  TCP_FLAGS  \\\n","0             0.0      9672        416       11         8         25   \n","1             0.0      1776        104        6         2         25   \n","2             1.0      1842       1236       26        22         25   \n","3             0.0       528       8824       10        12         27   \n","4             1.0      1786       2340       32        34         25   \n","...           ...       ...        ...      ...       ...        ...   \n","1623113       0.0       130        162        2         2          0   \n","1623114       1.0      2044       2404       36        34         26   \n","1623115       0.0       320       1918        6         8         27   \n","1623116       0.0       528       8824       10        12         27   \n","1623117       0.0       216        112        4         2         18   \n","\n","         FLOW_DURATION_MILLISECONDS  Label  Attack  \n","0                                15      0  Benign  \n","1                                 0      0  Benign  \n","2                              1111      0  Benign  \n","3                               124      0  Benign  \n","4                              1459      0  Benign  \n","...                             ...    ...     ...  \n","1623113                           0      0  Benign  \n","1623114                           0      0  Benign  \n","1623115                           0      0  Benign  \n","1623116                           0      0  Benign  \n","1623117                           0      0  Benign  \n","\n","[1623118 rows x 14 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Define the path to the CSV file\n","path = \"/content/drive/MyDrive/QNN/archive/\"\n","csv_filename = f\"{path}NF-UNSW-NB15.csv\"\n","\n","# Load the CSV file\n","df = pd.read_csv(csv_filename, low_memory=False)\n","\n","# Display the summary of the dataframe\n","print(\"\\nSummary of the CSV DataFrame:\")\n","df"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1725963963139,"user":{"displayName":"ritn B","userId":"17631196088925960099"},"user_tz":300},"id":"-Cb6CluWYPn3"},"outputs":[],"source":["# 1. 특성 선택\n","# 필요 없는 열 제거 (소스 및 목적지 IP 주소와 포트)\n","selected_features = [\n","    'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'OUT_BYTES',\n","    'IN_PKTS', 'OUT_PKTS', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS', 'Label'\n","]\n","df_selected = df[selected_features]\n","\n","# 2. 불균형 데이터 처리\n","# 악성 샘플과 정상 샘플을 분리\n","benign = df_selected[df_selected['Label'] == 0]\n","malicious = df_selected[df_selected['Label'] == 1]\n","\n","# 정상 샘플을 악성 샘플 수에 맞게 리샘플링\n","benign_downsampled = resample(benign, replace=False, n_samples=len(malicious), random_state=123)\n","\n","# 악성 샘플과 리샘플링된 정상 샘플을 합침\n","df_balanced = pd.concat([benign_downsampled, malicious])\n","\n","# 3. 데이터 분할\n","train, test = train_test_split(df_balanced, test_size=0.15, random_state=1)\n","\n","# 4. 특성 인코딩\n","# 각 특성 값을 양자 정보로 인코딩\n","def encode_features(df, features):\n","    df_encoded = df.copy()\n","    for feature in features:\n","        if feature in df_encoded.columns:\n","            max_value = df_encoded[feature].max()\n","            df_encoded[feature] = df_encoded[feature] / max_value * np.pi\n","            df_encoded[feature] = np.round(df_encoded[feature] / 0.25) * 0.25  # 양자화\n","    return df_encoded\n","\n","features_to_encode = ['PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'OUT_BYTES',\n","                      'IN_PKTS', 'OUT_PKTS', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS']\n","\n","train_encoded = encode_features(train, features_to_encode)\n","test_encoded = encode_features(test, features_to_encode)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1725963963139,"user":{"displayName":"ritn B","userId":"17631196088925960099"},"user_tz":300},"id":"FdcXs0dUYWCo","outputId":"5a8076ca-d758-412f-db26-31119ea7124d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_encoded"},"text/html":["\n","  \u003cdiv id=\"df-de193b07-ace6-4434-8eca-93957134f335\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ePROTOCOL\u003c/th\u003e\n","      \u003cth\u003eL7_PROTO\u003c/th\u003e\n","      \u003cth\u003eIN_BYTES\u003c/th\u003e\n","      \u003cth\u003eOUT_BYTES\u003c/th\u003e\n","      \u003cth\u003eIN_PKTS\u003c/th\u003e\n","      \u003cth\u003eOUT_PKTS\u003c/th\u003e\n","      \u003cth\u003eTCP_FLAGS\u003c/th\u003e\n","      \u003cth\u003eFLOW_DURATION_MILLISECONDS\u003c/th\u003e\n","      \u003cth\u003eLabel\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e888809\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e2.75\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e549273\u003c/th\u003e\n","      \u003ctd\u003e3.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e967695\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e2.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e847258\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e2.75\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e584324\u003c/th\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e17442\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e2.75\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e536827\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e2.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e211970\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e2.75\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e90433\u003c/th\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e808984\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e2.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e123090 rows × 9 columns\u003c/p\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de193b07-ace6-4434-8eca-93957134f335')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-de193b07-ace6-4434-8eca-93957134f335 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-de193b07-ace6-4434-8eca-93957134f335');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","\u003cdiv id=\"df-92085777-540c-45a8-802b-b68e31ed57b1\"\u003e\n","  \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-92085777-540c-45a8-802b-b68e31ed57b1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","  \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","  \u003cscript\u003e\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() =\u003e {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-92085777-540c-45a8-802b-b68e31ed57b1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  \u003c/script\u003e\n","\u003c/div\u003e\n","\n","  \u003cdiv id=\"id_e60f98cc-1a0e-4d32-9353-619c8db84170\"\u003e\n","    \u003cstyle\u003e\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    \u003c/style\u003e\n","    \u003cbutton class=\"colab-df-generate\" onclick=\"generateWithVariable('train_encoded')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","    \u003cscript\u003e\n","      (() =\u003e {\n","      const buttonEl =\n","        document.querySelector('#id_e60f98cc-1a0e-4d32-9353-619c8db84170 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () =\u003e {\n","        google.colab.notebook.generateWithVariable('train_encoded');\n","      }\n","      })();\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["        PROTOCOL  L7_PROTO  IN_BYTES  OUT_BYTES  IN_PKTS  OUT_PKTS  TCP_FLAGS  \\\n","888809      0.00      0.50       0.0       0.00      0.0      0.00       2.75   \n","549273      3.00      0.00       0.0       0.00      0.0      0.00       0.00   \n","967695      0.00      0.00       0.0       0.00      0.0      0.00       2.00   \n","847258      0.00      0.50       0.0       0.25      0.0      0.25       2.75   \n","584324      0.25      0.25       0.0       0.00      0.0      0.00       0.00   \n","...          ...       ...       ...        ...      ...       ...        ...   \n","17442       0.00      0.00       0.0       0.00      0.0      0.00       2.75   \n","536827      0.00      0.25       0.0       0.00      0.0      0.00       2.00   \n","211970      0.00      0.00       0.0       0.00      0.0      0.00       2.75   \n","90433       0.25      0.00       0.0       0.00      0.0      0.00       0.00   \n","808984      0.00      0.25       0.0       0.00      0.0      0.00       2.00   \n","\n","        FLOW_DURATION_MILLISECONDS  Label  \n","888809                         0.0      0  \n","549273                         0.0      1  \n","967695                         0.0      1  \n","847258                         0.0      0  \n","584324                         0.0      0  \n","...                            ...    ...  \n","17442                          0.0      1  \n","536827                         0.0      1  \n","211970                         0.0      0  \n","90433                          0.0      0  \n","808984                         0.0      1  \n","\n","[123090 rows x 9 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_encoded"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1725963963139,"user":{"displayName":"ritn B","userId":"17631196088925960099"},"user_tz":300},"id":"exsBzpd4YXqh","outputId":"7ed80a06-72b9-4e9d-e454-17d05fdad5cc"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"test_encoded\",\n  \"rows\": 21722,\n  \"fields\": [\n    {\n      \"column\": \"PROTOCOL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47478962699140154,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          1.5,\n          1.75,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L7_PROTO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36590982505486147,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          3.25,\n          0.75,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IN_BYTES\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05283702122897669,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.5,\n          0.25,\n          1.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OUT_BYTES\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054143265487618414,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.25,\n          0.25,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IN_PKTS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.055327460258338006,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.5,\n          0.25,\n          1.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OUT_PKTS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057828639600785624,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.25,\n          0.25,\n          3.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TCP_FLAGS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4012831967019574,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.75,\n          0.0,\n          2.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLOW_DURATION_MILLISECONDS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2701615442898893,\n        \"min\": 0.0,\n        \"max\": 3.25,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          3.25,\n          1.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"test_encoded"},"text/html":["\n","  \u003cdiv id=\"df-6791bb84-7c79-4a32-b8df-f31b763d2809\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ePROTOCOL\u003c/th\u003e\n","      \u003cth\u003eL7_PROTO\u003c/th\u003e\n","      \u003cth\u003eIN_BYTES\u003c/th\u003e\n","      \u003cth\u003eOUT_BYTES\u003c/th\u003e\n","      \u003cth\u003eIN_PKTS\u003c/th\u003e\n","      \u003cth\u003eOUT_PKTS\u003c/th\u003e\n","      \u003cth\u003eTCP_FLAGS\u003c/th\u003e\n","      \u003cth\u003eFLOW_DURATION_MILLISECONDS\u003c/th\u003e\n","      \u003cth\u003eLabel\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1587394\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e3.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1305802\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e3.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e839286\u003c/th\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e689916\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e3.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e960348\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e3.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e813051\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e3.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1429767\u003c/th\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e86295\u003c/th\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e2.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e376879\u003c/th\u003e\n","      \u003ctd\u003e1.75\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e354691\u003c/th\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e21722 rows × 9 columns\u003c/p\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6791bb84-7c79-4a32-b8df-f31b763d2809')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-6791bb84-7c79-4a32-b8df-f31b763d2809 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6791bb84-7c79-4a32-b8df-f31b763d2809');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","\u003cdiv id=\"df-74a79e79-2c44-4cad-9f98-0f37b811addf\"\u003e\n","  \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-74a79e79-2c44-4cad-9f98-0f37b811addf')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","  \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","  \u003cscript\u003e\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() =\u003e {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-74a79e79-2c44-4cad-9f98-0f37b811addf button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  \u003c/script\u003e\n","\u003c/div\u003e\n","\n","  \u003cdiv id=\"id_de899e53-ed80-4b68-8190-11f2ec781c63\"\u003e\n","    \u003cstyle\u003e\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    \u003c/style\u003e\n","    \u003cbutton class=\"colab-df-generate\" onclick=\"generateWithVariable('test_encoded')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","    \u003cscript\u003e\n","      (() =\u003e {\n","      const buttonEl =\n","        document.querySelector('#id_de899e53-ed80-4b68-8190-11f2ec781c63 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () =\u003e {\n","        google.colab.notebook.generateWithVariable('test_encoded');\n","      }\n","      })();\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["         PROTOCOL  L7_PROTO  IN_BYTES  OUT_BYTES  IN_PKTS  OUT_PKTS  \\\n","1587394      0.00      0.00       0.0        0.0      0.0      0.00   \n","1305802      0.00      0.00       0.0        0.0      0.0      0.00   \n","839286       0.25      0.25       0.0        0.0      0.0      0.00   \n","689916       0.00      0.00       0.0        0.0      0.0      0.00   \n","960348       0.00      0.00       0.0        0.0      0.0      0.00   \n","...           ...       ...       ...        ...      ...       ...   \n","813051       0.00      0.00       0.0        0.0      0.0      0.25   \n","1429767      0.25      0.00       0.0        0.0      0.0      0.00   \n","86295        0.00      0.25       0.0        0.0      0.0      0.00   \n","376879       1.75      0.00       0.0        0.0      0.0      0.00   \n","354691       0.25      0.25       0.0        0.0      0.0      0.00   \n","\n","         TCP_FLAGS  FLOW_DURATION_MILLISECONDS  Label  \n","1587394       3.25                         0.0      0  \n","1305802       3.25                         0.0      0  \n","839286        0.00                         0.0      0  \n","689916        3.25                         0.0      1  \n","960348        3.25                         0.0      0  \n","...            ...                         ...    ...  \n","813051        3.25                         0.0      1  \n","1429767       0.00                         0.0      0  \n","86295         2.25                         0.0      1  \n","376879        0.00                         0.0      1  \n","354691        0.00                         0.0      0  \n","\n","[21722 rows x 9 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["test_encoded"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1725963963139,"user":{"displayName":"ritn B","userId":"17631196088925960099"},"user_tz":300},"id":"U_CCj6PiUb1E"},"outputs":[],"source":["# import cirq\n","# import tensorflow as tf\n","# import tensorflow_quantum as tfq\n","# import sympy\n","# import matplotlib.pyplot as plt\n","# from keras.callbacks import Callback\n","\n","# # 하이퍼파라미터 정의\n","# NUM_QUBITS = 4  # 양자 비트 수\n","# NUM_LAYERS = 2  # QNN 레이어 수\n","# LEARNING_RATE = 0.02\n","# BATCH_SIZE = 32\n","# EPOCHS = 10\n","# ACTIVATION_FUNCTION = 'relu'  # 활성화 함수 ('relu', 'sigmoid', 'tanh', 등)\n","# LOSS_FUNCTION = 'binary_crossentropy'  # 손실 함수 ('binary_crossentropy', 'categorical_crossentropy', 등)\n","# OPTIMIZER = 'adam'  # 옵티마이저 ('adam', 'sgd', 'rmsprop', 등)\n","\n","# # 양자 회로 생성 함수\n","# def create_quantum_model(num_qubits, num_layers):\n","#     qubits = [cirq.GridQubit(i, 0) for i in range(num_qubits)]\n","#     circuit = cirq.Circuit()\n","\n","#     # 각 특성값을 양자 회로에 인코딩\n","#     for i in range(num_qubits):\n","#         theta = sympy.Symbol(f'theta_{i}')\n","#         circuit.append(cirq.rx(theta).on(qubits[i]))\n","\n","#     # QNN 레이어 추가\n","#     for _ in range(num_layers):\n","#         for i in range(num_qubits - 1):\n","#             circuit.append(cirq.XX(qubits[i], qubits[i + 1]))\n","#             circuit.append(cirq.YY(qubits[i], qubits[i + 1]))\n","\n","#     # 측정 연산 추가\n","#     readout = cirq.Z(qubits[0])\n","#     return circuit, readout\n","\n","# # QNN 모델 생성 함수\n","# def build_qnn_model(num_qubits, num_layers, learning_rate, activation_function, loss_function, optimizer):\n","#     circuit, readout_op = create_quantum_model(num_qubits, num_layers)\n","#     qnn_model = tf.keras.Sequential([\n","#         tf.keras.layers.Input(shape=(), dtype=tf.dtypes.string),\n","#         tfq.layers.PQC(circuit, readout_op),\n","#         tf.keras.layers.Dense(1, activation=activation_function)\n","#     ])\n","\n","#     # 옵티마이저 설정\n","#     if optimizer == 'adam':\n","#         optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","#     elif optimizer == 'sgd':\n","#         optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n","#     elif optimizer == 'rmsprop':\n","#         optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n","#     else:\n","#         raise ValueError(\"Unknown optimizer\")\n","\n","#     qnn_model.compile(optimizer=optimizer,\n","#                       loss=loss_function, metrics=['accuracy'])\n","#     return qnn_model\n","\n","# # 배치마다 loss를 기록하는 콜백 클래스\n","# class BatchLossHistory(Callback):\n","#     def on_train_begin(self, logs={}):\n","#         self.batch_losses = []  # 각 배치의 loss를 기록할 리스트\n","#         self.epoch_losses = []  # 각 에포크의 평균 loss를 기록할 리스트\n","\n","#     def on_batch_end(self, batch, logs={}):\n","#         self.batch_losses.append(logs.get('loss'))  # 배치가 끝날 때마다 loss 기록\n","\n","#     def on_epoch_end(self, epoch, logs={}):\n","#         self.epoch_losses.append(logs.get('loss'))  # 에포크가 끝날 때마다 평균 loss 기록\n","\n","# # 데이터셋 준비 (이전 단계에서 인코딩된 train_encoded, test_encoded 사용)\n","# x_train = train_encoded.drop(columns=['Label']).values.tolist()\n","# y_train = train_encoded['Label'].values\n","# x_test = test_encoded.drop(columns=['Label']).values.tolist()\n","# y_test = test_encoded['Label'].values\n","\n","# # 데이터를 TensorFlow Quantum 포맷으로 변환\n","# def convert_to_tensor(data):\n","#     return tfq.convert_to_tensor([\n","#         cirq.Circuit(cirq.rx(x)(cirq.GridQubit(i, 0)) for i, x in enumerate(sample)) for sample in data\n","#     ])\n","\n","# x_train_tfcirc = convert_to_tensor(x_train)\n","# x_test_tfcirc = convert_to_tensor(x_test)\n","\n","# # 모델 구성\n","# model = build_qnn_model(NUM_QUBITS, NUM_LAYERS, LEARNING_RATE, ACTIVATION_FUNCTION, LOSS_FUNCTION, OPTIMIZER)\n","\n","# # 커스텀 콜백 생성\n","# batch_loss_history = BatchLossHistory()\n","\n","# # 모델 학습\n","# history = model.fit(x_train_tfcirc, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n","#                     validation_data=(x_test_tfcirc, y_test), callbacks=[batch_loss_history])\n","\n","# # 테스트 손실 기록\n","# test_loss, test_acc = model.evaluate(x_test_tfcirc, y_test)\n","\n","# # 테스트 손실 출력\n","# print(f\"Test Loss: {test_loss}\")\n","# print(f\"Test Accuracy: {test_acc}\")\n","\n","# # # 배치별 loss 기록 그래프 출력\n","# # plt.figure(figsize=(12, 5))\n","# # plt.subplot(1, 2, 1)\n","# # plt.plot(batch_loss_history.batch_losses, label='Batch Loss during Training')\n","# # plt.xlabel('Batch')\n","# # plt.ylabel('Loss')\n","# # plt.title('Batch Loss during Training')\n","# # plt.legend()\n","\n","# # # 에포크별 손실 변화 그래프 출력\n","# # plt.subplot(1, 2, 2)\n","# # plt.plot(batch_loss_history.epoch_losses, label='Epoch Loss')\n","# # plt.xlabel('Epochs')\n","# # plt.ylabel('Loss')\n","# # plt.title('Loss at the End of Each Epoch')\n","# # plt.legend()\n","\n","# # plt.show()\n","\n","# # # 전체 에포크에 대한 정확도 그래프 출력\n","# # plt.plot(history.history['accuracy'], label='Train Accuracy')\n","# # plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","# # plt.xlabel('Epochs')\n","# # plt.ylabel('Accuracy')\n","# # plt.legend()\n","# # plt.show()\n","\n","# # 테스트 손실 수치 출력\n","# print(\"Validation Loss over Epochs:\")\n","# for epoch, loss in enumerate(history.history['val_loss'], 1):\n","#     print(f\"Epoch {epoch}: {loss:.4f}\")\n","\n","# # 테스트 손실 그래프 출력\n","# plt.plot(history.history['val_loss'], label='Validation Loss')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Loss')\n","# plt.title('Validation Loss over Epochs')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"UkP2Tt6ad3j2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training with 2 layers, 0.01 learning rate, relu activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 79s 20ms/step - loss: 0.7324 - accuracy: 0.5208 - val_loss: 0.6571 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 76s 20ms/step - loss: 0.6572 - accuracy: 0.5291 - val_loss: 0.6541 - val_accuracy: 0.5757\n","Epoch 3/10\n","3847/3847 [==============================] - 76s 20ms/step - loss: 0.6544 - accuracy: 0.5472 - val_loss: 0.6514 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 75s 20ms/step - loss: 0.6525 - accuracy: 0.5529 - val_loss: 0.6503 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 75s 20ms/step - loss: 0.6518 - accuracy: 0.5589 - val_loss: 0.6495 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 75s 19ms/step - loss: 0.6509 - accuracy: 0.5603 - val_loss: 0.6475 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 76s 20ms/step - loss: 0.6516 - accuracy: 0.5608 - val_loss: 0.6482 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 75s 20ms/step - loss: 0.6510 - accuracy: 0.5607 - val_loss: 0.6501 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 75s 20ms/step - loss: 0.6524 - accuracy: 0.5612 - val_loss: 0.6469 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 75s 20ms/step - loss: 0.6542 - accuracy: 0.5562 - val_loss: 0.6519 - val_accuracy: 0.5691\n","679/679 [==============================] - 7s 10ms/step - loss: 0.6519 - accuracy: 0.5691\n","Training with 2 layers, 0.01 learning rate, relu activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["3847/3847 [==============================] - 68s 17ms/step - loss: 7.5159 - accuracy: 0.5071 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 2/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 3/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 4/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 5/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 6/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 7/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 8/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 9/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 10/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","679/679 [==============================] - 7s 10ms/step - loss: 7.7053 - accuracy: 0.4947\n","Training with 2 layers, 0.01 learning rate, relu activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes \u003e 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 7s 10ms/step - loss: nan - accuracy: 0.5053\n","Training with 2 layers, 0.01 learning rate, relu activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 6s 9ms/step - loss: nan - accuracy: 0.5053\n","Training with 2 layers, 0.01 learning rate, sigmoid activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 71s 18ms/step - loss: 0.6630 - accuracy: 0.5323 - val_loss: 0.6568 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6567 - accuracy: 0.5449 - val_loss: 0.6547 - val_accuracy: 0.5757\n","Epoch 3/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6551 - accuracy: 0.5544 - val_loss: 0.6544 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6540 - accuracy: 0.5620 - val_loss: 0.6525 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6532 - accuracy: 0.5636 - val_loss: 0.6522 - val_accuracy: 0.5251\n","Epoch 6/10\n","3847/3847 [==============================] - 70s 18ms/step - loss: 0.6526 - accuracy: 0.5635 - val_loss: 0.6515 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6520 - accuracy: 0.5659 - val_loss: 0.6507 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 70s 18ms/step - loss: 0.6517 - accuracy: 0.5660 - val_loss: 0.6501 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6512 - accuracy: 0.5677 - val_loss: 0.6497 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6511 - accuracy: 0.5672 - val_loss: 0.6495 - val_accuracy: 0.5757\n","679/679 [==============================] - 6s 9ms/step - loss: 0.6495 - accuracy: 0.5757\n","Training with 2 layers, 0.01 learning rate, sigmoid activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.7082 - accuracy: 0.4921 - val_loss: 0.6928 - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6873 - accuracy: 0.5417 - val_loss: 0.6809 - val_accuracy: 0.5627\n","Epoch 3/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6750 - accuracy: 0.5635 - val_loss: 0.6692 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6665 - accuracy: 0.5627 - val_loss: 0.6632 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6627 - accuracy: 0.5299 - val_loss: 0.6608 - val_accuracy: 0.5251\n","Epoch 6/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6611 - accuracy: 0.5185 - val_loss: 0.6595 - val_accuracy: 0.5251\n","Epoch 7/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6602 - accuracy: 0.5188 - val_loss: 0.6588 - val_accuracy: 0.5251\n","Epoch 8/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6596 - accuracy: 0.5181 - val_loss: 0.6586 - val_accuracy: 0.5251\n","Epoch 9/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6591 - accuracy: 0.5184 - val_loss: 0.6578 - val_accuracy: 0.5251\n","Epoch 10/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6587 - accuracy: 0.5215 - val_loss: 0.6573 - val_accuracy: 0.5251\n","679/679 [==============================] - 7s 10ms/step - loss: 0.6573 - accuracy: 0.5251\n","Training with 2 layers, 0.01 learning rate, sigmoid activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 68s 17ms/step - loss: 0.0000e+00 - accuracy: 0.5058 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 2/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 3/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 4/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 5/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 6/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 7/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 8/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 9/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 10/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 7s 10ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 2 layers, 0.01 learning rate, sigmoid activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4985 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 7s 10ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 2 layers, 0.02 learning rate, relu activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6205 - accuracy: 0.4999 - val_loss: 7.7054 - val_accuracy: 0.4947\n","Epoch 2/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 3/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 4/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 5/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 6/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 7/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 8/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 9/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 10/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","679/679 [==============================] - 7s 10ms/step - loss: 7.7053 - accuracy: 0.4947\n","Training with 2 layers, 0.02 learning rate, relu activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.5862 - accuracy: 0.5021 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 2/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 3/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 4/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 5/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 6/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 7/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 8/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 9/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 10/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","679/679 [==============================] - 7s 10ms/step - loss: 7.7053 - accuracy: 0.4947\n","Training with 2 layers, 0.02 learning rate, relu activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 70s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 70s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 6s 9ms/step - loss: nan - accuracy: 0.5053\n","Training with 2 layers, 0.02 learning rate, relu activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 68s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 6s 9ms/step - loss: nan - accuracy: 0.5053\n","Training with 2 layers, 0.02 learning rate, sigmoid activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6616 - accuracy: 0.5377 - val_loss: 0.6560 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6551 - accuracy: 0.5530 - val_loss: 0.6524 - val_accuracy: 0.5757\n","Epoch 3/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6535 - accuracy: 0.5584 - val_loss: 0.6512 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6527 - accuracy: 0.5605 - val_loss: 0.6522 - val_accuracy: 0.5691\n","Epoch 5/10\n","3847/3847 [==============================] - 70s 18ms/step - loss: 0.6518 - accuracy: 0.5615 - val_loss: 0.6507 - val_accuracy: 0.5691\n","Epoch 6/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6512 - accuracy: 0.5641 - val_loss: 0.6492 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6508 - accuracy: 0.5661 - val_loss: 0.6492 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6505 - accuracy: 0.5650 - val_loss: 0.6485 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6500 - accuracy: 0.5636 - val_loss: 0.6480 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6497 - accuracy: 0.5653 - val_loss: 0.6484 - val_accuracy: 0.5757\n","679/679 [==============================] - 6s 10ms/step - loss: 0.6484 - accuracy: 0.5757\n","Training with 2 layers, 0.02 learning rate, sigmoid activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.6783 - accuracy: 0.5563 - val_loss: 0.6665 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6637 - accuracy: 0.5325 - val_loss: 0.6605 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6607 - accuracy: 0.5183 - val_loss: 0.6587 - val_accuracy: 0.5251\n","Epoch 4/10\n","3847/3847 [==============================] - 67s 18ms/step - loss: 0.6594 - accuracy: 0.5198 - val_loss: 0.6577 - val_accuracy: 0.5251\n","Epoch 5/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6585 - accuracy: 0.5224 - val_loss: 0.6572 - val_accuracy: 0.5251\n","Epoch 6/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6579 - accuracy: 0.5243 - val_loss: 0.6565 - val_accuracy: 0.5251\n","Epoch 7/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6573 - accuracy: 0.5286 - val_loss: 0.6559 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.6568 - accuracy: 0.5383 - val_loss: 0.6556 - val_accuracy: 0.5251\n","Epoch 9/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6564 - accuracy: 0.5438 - val_loss: 0.6553 - val_accuracy: 0.5251\n","Epoch 10/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.6561 - accuracy: 0.5509 - val_loss: 0.6549 - val_accuracy: 0.5757\n","679/679 [==============================] - 7s 10ms/step - loss: 0.6549 - accuracy: 0.5757\n","Training with 2 layers, 0.02 learning rate, sigmoid activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.5027 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 2/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 3/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 4/10\n","3847/3847 [==============================] - 66s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 5/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 6/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 8/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4994 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 9/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4994 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 10/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4994 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","679/679 [==============================] - 7s 10ms/step - loss: 0.0000e+00 - accuracy: 0.5062\n","Training with 2 layers, 0.02 learning rate, sigmoid activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.0000e+00 - accuracy: 0.5083 - val_loss: 0.0000e+00 - val_accuracy: 0.5116\n","Epoch 2/10\n","3847/3847 [==============================] - 67s 17ms/step - loss: 0.0000e+00 - accuracy: 0.5020 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 3/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 4/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 5/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4994 - val_loss: 0.0000e+00 - val_accuracy: 0.5108\n","Epoch 6/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 68s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 69s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 7s 10ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 3 layers, 0.01 learning rate, relu activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.6686 - accuracy: 0.5224 - val_loss: 0.6557 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6547 - accuracy: 0.5439 - val_loss: 0.6506 - val_accuracy: 0.5757\n","Epoch 3/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6528 - accuracy: 0.5521 - val_loss: 0.6493 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6516 - accuracy: 0.5600 - val_loss: 0.6486 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6513 - accuracy: 0.5610 - val_loss: 0.6474 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6532 - accuracy: 0.5573 - val_loss: 0.6490 - val_accuracy: 0.5691\n","Epoch 7/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.6495 - accuracy: 0.5636 - val_loss: 0.6500 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6520 - accuracy: 0.5623 - val_loss: 0.6513 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6521 - accuracy: 0.5621 - val_loss: 0.6509 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6534 - accuracy: 0.5617 - val_loss: 0.6495 - val_accuracy: 0.5757\n","679/679 [==============================] - 8s 12ms/step - loss: 0.6495 - accuracy: 0.5757\n","Training with 3 layers, 0.01 learning rate, relu activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.7361 - accuracy: 0.5305 - val_loss: 0.6541 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6547 - accuracy: 0.5322 - val_loss: 0.6533 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6537 - accuracy: 0.5455 - val_loss: 0.6515 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6529 - accuracy: 0.5549 - val_loss: 0.6520 - val_accuracy: 0.5251\n","Epoch 5/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6522 - accuracy: 0.5592 - val_loss: 0.6502 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6514 - accuracy: 0.5611 - val_loss: 0.6494 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6508 - accuracy: 0.5641 - val_loss: 0.6489 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6503 - accuracy: 0.5651 - val_loss: 0.6492 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6498 - accuracy: 0.5669 - val_loss: 0.6486 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6496 - accuracy: 0.5669 - val_loss: 0.6478 - val_accuracy: 0.5757\n","679/679 [==============================] - 8s 12ms/step - loss: 0.6478 - accuracy: 0.5757\n","Training with 3 layers, 0.01 learning rate, relu activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 8s 12ms/step - loss: nan - accuracy: 0.5053\n","Training with 3 layers, 0.01 learning rate, relu activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 8s 12ms/step - loss: nan - accuracy: 0.5053\n","Training with 3 layers, 0.01 learning rate, sigmoid activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6651 - accuracy: 0.5301 - val_loss: 0.6577 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6569 - accuracy: 0.5448 - val_loss: 0.6545 - val_accuracy: 0.5757\n","Epoch 3/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6551 - accuracy: 0.5544 - val_loss: 0.6538 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6541 - accuracy: 0.5603 - val_loss: 0.6535 - val_accuracy: 0.5251\n","Epoch 5/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6533 - accuracy: 0.5631 - val_loss: 0.6534 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.6526 - accuracy: 0.5651 - val_loss: 0.6509 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6521 - accuracy: 0.5647 - val_loss: 0.6506 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 88s 23ms/step - loss: 0.6516 - accuracy: 0.5659 - val_loss: 0.6502 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6512 - accuracy: 0.5672 - val_loss: 0.6499 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6509 - accuracy: 0.5671 - val_loss: 0.6497 - val_accuracy: 0.5757\n","679/679 [==============================] - 8s 12ms/step - loss: 0.6497 - accuracy: 0.5757\n","Training with 3 layers, 0.01 learning rate, sigmoid activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 87s 23ms/step - loss: 0.7166 - accuracy: 0.4787 - val_loss: 0.6949 - val_accuracy: 0.5025\n","Epoch 2/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6884 - accuracy: 0.5055 - val_loss: 0.6799 - val_accuracy: 0.5243\n","Epoch 3/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6745 - accuracy: 0.5180 - val_loss: 0.6687 - val_accuracy: 0.5251\n","Epoch 4/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6676 - accuracy: 0.5181 - val_loss: 0.6644 - val_accuracy: 0.5251\n","Epoch 5/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.6646 - accuracy: 0.5181 - val_loss: 0.6624 - val_accuracy: 0.5251\n","Epoch 6/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6629 - accuracy: 0.5181 - val_loss: 0.6609 - val_accuracy: 0.5251\n","Epoch 7/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6618 - accuracy: 0.5181 - val_loss: 0.6600 - val_accuracy: 0.5251\n","Epoch 8/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6609 - accuracy: 0.5181 - val_loss: 0.6592 - val_accuracy: 0.5251\n","Epoch 9/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6602 - accuracy: 0.5181 - val_loss: 0.6587 - val_accuracy: 0.5251\n","Epoch 10/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.6596 - accuracy: 0.5181 - val_loss: 0.6582 - val_accuracy: 0.5251\n","679/679 [==============================] - 8s 12ms/step - loss: 0.6582 - accuracy: 0.5251\n","Training with 3 layers, 0.01 learning rate, sigmoid activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.0000e+00 - accuracy: 0.5006 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 2/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 3/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 4/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4994 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4994 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4993 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 8/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 9/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 8s 11ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 3 layers, 0.01 learning rate, sigmoid activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4971 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 79s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 8s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 3 layers, 0.02 learning rate, relu activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: 7.6181 - accuracy: 0.5001 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 2/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 3/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 4/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 5/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 6/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 7/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 8/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 9/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 10/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","679/679 [==============================] - 8s 12ms/step - loss: 7.7053 - accuracy: 0.4947\n","Training with 3 layers, 0.02 learning rate, relu activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: 0.6607 - accuracy: 0.5400 - val_loss: 0.6517 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 83s 21ms/step - loss: 0.6535 - accuracy: 0.5503 - val_loss: 0.6514 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6520 - accuracy: 0.5572 - val_loss: 0.6493 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6508 - accuracy: 0.5607 - val_loss: 0.6492 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.6507 - accuracy: 0.5602 - val_loss: 0.6490 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6506 - accuracy: 0.5612 - val_loss: 0.6474 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6509 - accuracy: 0.5636 - val_loss: 0.6471 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: 0.6507 - accuracy: 0.5632 - val_loss: 0.6504 - val_accuracy: 0.5453\n","Epoch 9/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6525 - accuracy: 0.5614 - val_loss: 0.6496 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6515 - accuracy: 0.5622 - val_loss: 0.6556 - val_accuracy: 0.5691\n","679/679 [==============================] - 8s 12ms/step - loss: 0.6556 - accuracy: 0.5691\n","Training with 3 layers, 0.02 learning rate, relu activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 8s 12ms/step - loss: nan - accuracy: 0.5053\n","Training with 3 layers, 0.02 learning rate, relu activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 81s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 80s 21ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 8s 11ms/step - loss: nan - accuracy: 0.5053\n","Training with 3 layers, 0.02 learning rate, sigmoid activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 84s 21ms/step - loss: 0.6601 - accuracy: 0.5440 - val_loss: 0.6556 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6552 - accuracy: 0.5533 - val_loss: 0.6537 - val_accuracy: 0.5691\n","Epoch 3/10\n","3847/3847 [==============================] - 83s 22ms/step - loss: 0.6534 - accuracy: 0.5586 - val_loss: 0.6511 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6527 - accuracy: 0.5605 - val_loss: 0.6502 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 82s 21ms/step - loss: 0.6520 - accuracy: 0.5616 - val_loss: 0.6500 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6512 - accuracy: 0.5626 - val_loss: 0.6495 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 92s 24ms/step - loss: 0.6508 - accuracy: 0.5646 - val_loss: 0.6509 - val_accuracy: 0.5453\n","Epoch 8/10\n","3847/3847 [==============================] - 91s 24ms/step - loss: 0.6502 - accuracy: 0.5654 - val_loss: 0.6493 - val_accuracy: 0.5691\n","Epoch 9/10\n","3847/3847 [==============================] - 87s 23ms/step - loss: 0.6501 - accuracy: 0.5657 - val_loss: 0.6480 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 87s 23ms/step - loss: 0.6495 - accuracy: 0.5654 - val_loss: 0.6532 - val_accuracy: 0.5453\n","679/679 [==============================] - 8s 12ms/step - loss: 0.6532 - accuracy: 0.5453\n","Training with 3 layers, 0.02 learning rate, sigmoid activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 87s 22ms/step - loss: 0.6711 - accuracy: 0.5585 - val_loss: 0.6631 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6620 - accuracy: 0.5258 - val_loss: 0.6603 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 87s 23ms/step - loss: 0.6601 - accuracy: 0.5208 - val_loss: 0.6585 - val_accuracy: 0.5251\n","Epoch 4/10\n","3847/3847 [==============================] - 88s 23ms/step - loss: 0.6591 - accuracy: 0.5193 - val_loss: 0.6574 - val_accuracy: 0.5251\n","Epoch 5/10\n","3847/3847 [==============================] - 88s 23ms/step - loss: 0.6582 - accuracy: 0.5250 - val_loss: 0.6568 - val_accuracy: 0.5251\n","Epoch 6/10\n","3847/3847 [==============================] - 89s 23ms/step - loss: 0.6576 - accuracy: 0.5300 - val_loss: 0.6571 - val_accuracy: 0.5251\n","Epoch 7/10\n","3847/3847 [==============================] - 89s 23ms/step - loss: 0.6571 - accuracy: 0.5349 - val_loss: 0.6557 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 88s 23ms/step - loss: 0.6567 - accuracy: 0.5405 - val_loss: 0.6556 - val_accuracy: 0.5251\n","Epoch 9/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.6563 - accuracy: 0.5437 - val_loss: 0.6550 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 88s 23ms/step - loss: 0.6559 - accuracy: 0.5486 - val_loss: 0.6547 - val_accuracy: 0.5757\n","679/679 [==============================] - 8s 12ms/step - loss: 0.6547 - accuracy: 0.5757\n","Training with 3 layers, 0.02 learning rate, sigmoid activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 87s 22ms/step - loss: 0.0000e+00 - accuracy: 0.5039 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 2/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 3/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 4/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 5/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 6/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 7/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 8/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 9/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 10/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","679/679 [==============================] - 9s 13ms/step - loss: 0.0000e+00 - accuracy: 0.5062\n","Training with 3 layers, 0.02 learning rate, sigmoid activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.0000e+00 - accuracy: 0.5057 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 2/10\n","3847/3847 [==============================] - 84s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 3/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 4/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 86s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 85s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 8s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 4 layers, 0.01 learning rate, relu activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.7288 - accuracy: 0.5289 - val_loss: 0.6545 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6554 - accuracy: 0.5389 - val_loss: 0.6510 - val_accuracy: 0.5757\n","Epoch 3/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6532 - accuracy: 0.5532 - val_loss: 0.6510 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6518 - accuracy: 0.5571 - val_loss: 0.6494 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6519 - accuracy: 0.5596 - val_loss: 0.6478 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6518 - accuracy: 0.5596 - val_loss: 0.6502 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6514 - accuracy: 0.5602 - val_loss: 0.6581 - val_accuracy: 0.4947\n","Epoch 8/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6519 - accuracy: 0.5607 - val_loss: 0.6471 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6523 - accuracy: 0.5637 - val_loss: 0.6499 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6527 - accuracy: 0.5632 - val_loss: 0.6521 - val_accuracy: 0.5691\n","679/679 [==============================] - 10s 14ms/step - loss: 0.6521 - accuracy: 0.5691\n","Training with 4 layers, 0.01 learning rate, relu activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 1.1116 - accuracy: 0.5217 - val_loss: 0.6557 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6554 - accuracy: 0.5262 - val_loss: 0.6538 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6545 - accuracy: 0.5356 - val_loss: 0.6521 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6535 - accuracy: 0.5480 - val_loss: 0.6517 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6526 - accuracy: 0.5571 - val_loss: 0.6510 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.6518 - accuracy: 0.5596 - val_loss: 0.6506 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6513 - accuracy: 0.5641 - val_loss: 0.6512 - val_accuracy: 0.5251\n","Epoch 8/10\n","3847/3847 [==============================] - 102s 26ms/step - loss: 0.6506 - accuracy: 0.5640 - val_loss: 0.6493 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6502 - accuracy: 0.5656 - val_loss: 0.6485 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 102s 26ms/step - loss: 0.6497 - accuracy: 0.5667 - val_loss: 0.6478 - val_accuracy: 0.5757\n","679/679 [==============================] - 10s 14ms/step - loss: 0.6478 - accuracy: 0.5757\n","Training with 4 layers, 0.01 learning rate, relu activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 10s 14ms/step - loss: nan - accuracy: 0.5053\n","Training with 4 layers, 0.01 learning rate, relu activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 9s 14ms/step - loss: nan - accuracy: 0.5053\n","Training with 4 layers, 0.01 learning rate, sigmoid activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 0.6674 - accuracy: 0.5215 - val_loss: 0.6572 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: 0.6573 - accuracy: 0.5407 - val_loss: 0.6574 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 0.6554 - accuracy: 0.5548 - val_loss: 0.6539 - val_accuracy: 0.5251\n","Epoch 4/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 0.6543 - accuracy: 0.5607 - val_loss: 0.6532 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.6534 - accuracy: 0.5609 - val_loss: 0.6544 - val_accuracy: 0.5453\n","Epoch 6/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: 0.6529 - accuracy: 0.5638 - val_loss: 0.6524 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: 0.6523 - accuracy: 0.5654 - val_loss: 0.6512 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.6517 - accuracy: 0.5669 - val_loss: 0.6504 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6514 - accuracy: 0.5668 - val_loss: 0.6516 - val_accuracy: 0.5251\n","Epoch 10/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: 0.6510 - accuracy: 0.5667 - val_loss: 0.6494 - val_accuracy: 0.5757\n","679/679 [==============================] - 9s 14ms/step - loss: 0.6494 - accuracy: 0.5757\n","Training with 4 layers, 0.01 learning rate, sigmoid activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: 0.7005 - accuracy: 0.5019 - val_loss: 0.6870 - val_accuracy: 0.5510\n","Epoch 2/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.6801 - accuracy: 0.5586 - val_loss: 0.6734 - val_accuracy: 0.5757\n","Epoch 3/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6691 - accuracy: 0.5685 - val_loss: 0.6651 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 94s 25ms/step - loss: 0.6639 - accuracy: 0.5365 - val_loss: 0.6617 - val_accuracy: 0.5251\n","Epoch 5/10\n","3847/3847 [==============================] - 94s 25ms/step - loss: 0.6618 - accuracy: 0.5181 - val_loss: 0.6600 - val_accuracy: 0.5251\n","Epoch 6/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6607 - accuracy: 0.5181 - val_loss: 0.6592 - val_accuracy: 0.5251\n","Epoch 7/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6599 - accuracy: 0.5182 - val_loss: 0.6585 - val_accuracy: 0.5251\n","Epoch 8/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.6594 - accuracy: 0.5181 - val_loss: 0.6579 - val_accuracy: 0.5251\n","Epoch 9/10\n","3847/3847 [==============================] - 94s 25ms/step - loss: 0.6589 - accuracy: 0.5181 - val_loss: 0.6576 - val_accuracy: 0.5251\n","Epoch 10/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6585 - accuracy: 0.5195 - val_loss: 0.6573 - val_accuracy: 0.5251\n","679/679 [==============================] - 9s 13ms/step - loss: 0.6573 - accuracy: 0.5251\n","Training with 4 layers, 0.01 learning rate, sigmoid activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4988 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 10s 14ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 4 layers, 0.01 learning rate, sigmoid activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4984 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 9s 14ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 4 layers, 0.02 learning rate, relu activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.7427 - accuracy: 0.5313 - val_loss: 0.6511 - val_accuracy: 0.5757\n","Epoch 2/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6547 - accuracy: 0.5481 - val_loss: 0.6521 - val_accuracy: 0.4947\n","Epoch 3/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6537 - accuracy: 0.5526 - val_loss: 0.6517 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6559 - accuracy: 0.5558 - val_loss: 0.6506 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6536 - accuracy: 0.5556 - val_loss: 0.6541 - val_accuracy: 0.5453\n","Epoch 6/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6539 - accuracy: 0.5580 - val_loss: 0.6607 - val_accuracy: 0.5453\n","Epoch 7/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: 0.6562 - accuracy: 0.5556 - val_loss: 0.6531 - val_accuracy: 0.5691\n","Epoch 8/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6536 - accuracy: 0.5617 - val_loss: 0.6490 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6540 - accuracy: 0.5563 - val_loss: 0.6495 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6535 - accuracy: 0.5592 - val_loss: 0.6494 - val_accuracy: 0.5757\n","679/679 [==============================] - 10s 14ms/step - loss: 0.6494 - accuracy: 0.5757\n","Training with 4 layers, 0.02 learning rate, relu activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 101s 26ms/step - loss: 0.6738 - accuracy: 0.5410 - val_loss: 0.6594 - val_accuracy: 0.4947\n","Epoch 2/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6536 - accuracy: 0.5492 - val_loss: 0.6515 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6519 - accuracy: 0.5576 - val_loss: 0.6561 - val_accuracy: 0.4947\n","Epoch 4/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.6511 - accuracy: 0.5609 - val_loss: 0.6488 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 100s 26ms/step - loss: 0.6504 - accuracy: 0.5622 - val_loss: 0.6492 - val_accuracy: 0.5691\n","Epoch 6/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 3.9980 - accuracy: 0.5312 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 7/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 8/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 9/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","Epoch 10/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: 7.6106 - accuracy: 0.5009 - val_loss: 7.7053 - val_accuracy: 0.4947\n","679/679 [==============================] - 9s 14ms/step - loss: 7.7053 - accuracy: 0.4947\n","Training with 4 layers, 0.02 learning rate, relu activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 98s 26ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 9s 14ms/step - loss: nan - accuracy: 0.5053\n","Training with 4 layers, 0.02 learning rate, relu activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 2/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 3/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 4/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 5/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 7/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 9/10\n","3847/3847 [==============================] - 97s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 98s 25ms/step - loss: nan - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5053\n","679/679 [==============================] - 9s 14ms/step - loss: nan - accuracy: 0.5053\n","Training with 4 layers, 0.02 learning rate, sigmoid activation, binary_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.6604 - accuracy: 0.5406 - val_loss: 0.6546 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 99s 26ms/step - loss: 0.6552 - accuracy: 0.5503 - val_loss: 0.6536 - val_accuracy: 0.5691\n","Epoch 3/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.6535 - accuracy: 0.5588 - val_loss: 0.6521 - val_accuracy: 0.5757\n","Epoch 4/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6525 - accuracy: 0.5602 - val_loss: 0.6510 - val_accuracy: 0.5757\n","Epoch 5/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6519 - accuracy: 0.5613 - val_loss: 0.6497 - val_accuracy: 0.5757\n","Epoch 6/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.6510 - accuracy: 0.5634 - val_loss: 0.6498 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6509 - accuracy: 0.5629 - val_loss: 0.6491 - val_accuracy: 0.5757\n","Epoch 8/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6503 - accuracy: 0.5644 - val_loss: 0.6491 - val_accuracy: 0.5757\n","Epoch 9/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.6502 - accuracy: 0.5654 - val_loss: 0.6477 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6497 - accuracy: 0.5650 - val_loss: 0.6476 - val_accuracy: 0.5757\n","679/679 [==============================] - 9s 14ms/step - loss: 0.6476 - accuracy: 0.5757\n","Training with 4 layers, 0.02 learning rate, sigmoid activation, binary_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 96s 25ms/step - loss: 0.6798 - accuracy: 0.5537 - val_loss: 0.6673 - val_accuracy: 0.5251\n","Epoch 2/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6639 - accuracy: 0.5328 - val_loss: 0.6607 - val_accuracy: 0.5251\n","Epoch 3/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6607 - accuracy: 0.5198 - val_loss: 0.6588 - val_accuracy: 0.5251\n","Epoch 4/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6595 - accuracy: 0.5199 - val_loss: 0.6577 - val_accuracy: 0.5251\n","Epoch 5/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6586 - accuracy: 0.5214 - val_loss: 0.6571 - val_accuracy: 0.5251\n","Epoch 6/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6579 - accuracy: 0.5237 - val_loss: 0.6564 - val_accuracy: 0.5757\n","Epoch 7/10\n","3847/3847 [==============================] - 95s 25ms/step - loss: 0.6573 - accuracy: 0.5328 - val_loss: 0.6560 - val_accuracy: 0.5251\n","Epoch 8/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6568 - accuracy: 0.5384 - val_loss: 0.6562 - val_accuracy: 0.5251\n","Epoch 9/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6565 - accuracy: 0.5445 - val_loss: 0.6552 - val_accuracy: 0.5757\n","Epoch 10/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.6561 - accuracy: 0.5474 - val_loss: 0.6549 - val_accuracy: 0.5757\n","679/679 [==============================] - 9s 13ms/step - loss: 0.6549 - accuracy: 0.5757\n","Training with 4 layers, 0.02 learning rate, sigmoid activation, categorical_crossentropy loss, adam optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 2/10\n","3847/3847 [==============================] - 92s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 3/10\n","3847/3847 [==============================] - 93s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4996 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 4/10\n","3847/3847 [==============================] - 93s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 5/10\n","3847/3847 [==============================] - 93s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 6/10\n","3847/3847 [==============================] - 93s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4994 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 7/10\n","3847/3847 [==============================] - 93s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4993 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 8/10\n","3847/3847 [==============================] - 93s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4993 - val_loss: 0.0000e+00 - val_accuracy: 0.5062\n","Epoch 9/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4993 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 10/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4992 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","679/679 [==============================] - 9s 14ms/step - loss: 0.0000e+00 - accuracy: 0.5053\n","Training with 4 layers, 0.02 learning rate, sigmoid activation, categorical_crossentropy loss, sgd optimizer\n","Epoch 1/10\n","3847/3847 [==============================] - 94s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4991 - val_loss: 0.0000e+00 - val_accuracy: 0.5053\n","Epoch 2/10\n","3411/3847 [=========================\u003e....] - ETA: 9s - loss: 0.0000e+00 - accuracy: 0.4990"]}],"source":["import cirq\n","import tensorflow as tf\n","import tensorflow_quantum as tfq\n","import sympy\n","import matplotlib.pyplot as plt\n","from keras.callbacks import Callback\n","\n","# 하이퍼파라미터 정의\n","HYPERPARAMS = {\n","    \"NUM_QUBITS\": 4,  # 양자 비트 수\n","    \"NUM_LAYERS_LIST\": [2, 3, 4],  # QNN 레이어 수 리스트\n","    \"LEARNING_RATE_LIST\": [0.01, 0.02],  # 학습률 리스트\n","    \"BATCH_SIZE\": 32,\n","    \"EPOCHS\": 10,\n","    \"ACTIVATION_FUNCTION_LIST\": ['relu', 'sigmoid'],  # 활성화 함수 리스트\n","    \"LOSS_FUNCTION_LIST\": ['binary_crossentropy', 'categorical_crossentropy'],  # 손실 함수 리스트\n","    \"OPTIMIZER_LIST\": ['adam', 'sgd']  # 옵티마이저 리스트\n","}\n","\n","# 양자 회로 생성 함수\n","def create_quantum_model(num_qubits, num_layers):\n","    qubits = [cirq.GridQubit(i, 0) for i in range(num_qubits)]\n","    circuit = cirq.Circuit()\n","\n","    # 각 특성값을 양자 회로에 인코딩\n","    for i in range(num_qubits):\n","        theta = sympy.Symbol(f'theta_{i}')\n","        circuit.append(cirq.rx(theta).on(qubits[i]))\n","\n","    # QNN 레이어 추가\n","    for _ in range(num_layers):\n","        for i in range(num_qubits - 1):\n","            circuit.append(cirq.XX(qubits[i], qubits[i + 1]))\n","            circuit.append(cirq.YY(qubits[i], qubits[i + 1]))\n","\n","    # 측정 연산 추가\n","    readout = cirq.Z(qubits[0])\n","    return circuit, readout\n","\n","# QNN 모델 생성 함수\n","def build_qnn_model(num_qubits, num_layers, activation_function):\n","    circuit, readout_op = create_quantum_model(num_qubits, num_layers)\n","    qnn_model = tf.keras.Sequential([\n","        tf.keras.layers.Input(shape=(), dtype=tf.dtypes.string),\n","        tfq.layers.PQC(circuit, readout_op),\n","        tf.keras.layers.Dense(1, activation=activation_function)\n","    ])\n","    return qnn_model\n","\n","# 배치마다 loss를 기록하는 콜백 클래스\n","class BatchLossHistory(Callback):\n","    def on_train_begin(self, logs={}):\n","        self.batch_losses = []  # 각 배치의 loss를 기록할 리스트\n","        self.epoch_losses = []  # 각 에포크의 평균 loss를 기록할 리스트\n","\n","    def on_batch_end(self, batch, logs={}):\n","        self.batch_losses.append(logs.get('loss'))  # 배치가 끝날 때마다 loss 기록\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.epoch_losses.append(logs.get('loss'))  # 에포크가 끝날 때마다 평균 loss 기록\n","\n","# 데이터셋 준비 (이전 단계에서 인코딩된 train_encoded, test_encoded 사용)\n","x_train = train_encoded.drop(columns=['Label']).values.tolist()\n","y_train = train_encoded['Label'].values\n","x_test = test_encoded.drop(columns=['Label']).values.tolist()\n","y_test = test_encoded['Label'].values\n","\n","# 데이터를 TensorFlow Quantum 포맷으로 변환\n","def convert_to_tensor(data):\n","    return tfq.convert_to_tensor([\n","        cirq.Circuit(cirq.rx(x)(cirq.GridQubit(i, 0)) for i, x in enumerate(sample)) for sample in data\n","    ])\n","\n","x_train_tfcirc = convert_to_tensor(x_train)\n","x_test_tfcirc = convert_to_tensor(x_test)\n","\n","# 테스트 손실을 저장할 딕셔너리\n","test_losses = {}\n","\n","# 각 하이퍼파라미터 조합에 대해 모델 학습 및 평가\n","for num_layers in HYPERPARAMS['NUM_LAYERS_LIST']:\n","    for learning_rate in HYPERPARAMS['LEARNING_RATE_LIST']:\n","        for activation_function in HYPERPARAMS['ACTIVATION_FUNCTION_LIST']:\n","            for loss_function in HYPERPARAMS['LOSS_FUNCTION_LIST']:\n","                for optimizer_name in HYPERPARAMS['OPTIMIZER_LIST']:\n","                    print(f\"Training with {num_layers} layers, {learning_rate} learning rate, {activation_function} activation, {loss_function} loss, {optimizer_name} optimizer\")\n","\n","                    # 모델 구성\n","                    model = build_qnn_model(\n","                        num_qubits=HYPERPARAMS['NUM_QUBITS'],\n","                        num_layers=num_layers,\n","                        activation_function=activation_function\n","                    )\n","\n","                    # 옵티마이저 설정\n","                    if optimizer_name == 'adam':\n","                        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","                    elif optimizer_name == 'sgd':\n","                        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n","\n","                    # 모델 컴파일\n","                    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n","\n","                    # 커스텀 콜백 생성\n","                    batch_loss_history = BatchLossHistory()\n","\n","                    # 모델 학습\n","                    model.fit(x_train_tfcirc, y_train, batch_size=HYPERPARAMS['BATCH_SIZE'], epochs=HYPERPARAMS['EPOCHS'],\n","                              validation_data=(x_test_tfcirc, y_test), callbacks=[batch_loss_history])\n","\n","                    # 테스트 셋 평가\n","                    test_loss, _ = model.evaluate(x_test_tfcirc, y_test)\n","\n","                    # 결과 저장 (하이퍼파라미터 조합을 키로)\n","                    hyperparam_combo = (num_layers, learning_rate, activation_function, loss_function, optimizer_name)\n","                    test_losses[hyperparam_combo] = test_loss\n","\n","# 테스트 손실 그래프 출력\n","plt.figure(figsize=(10, 6))\n","for hyperparam_combo, loss in test_losses.items():\n","    label = f\"Layers: {hyperparam_combo[0]}, LR: {hyperparam_combo[1]}, Act: {hyperparam_combo[2]}, Loss: {hyperparam_combo[3]}, Opt: {hyperparam_combo[4]}\"\n","    plt.plot([hyperparam_combo[0]], [loss], marker='o', label=label)\n","\n","plt.xlabel('Number of Layers')\n","plt.ylabel('Test Loss')\n","plt.title('Test Loss for Different Hyperparameter Combinations')\n","plt.legend(loc='best', bbox_to_anchor=(1, 1))\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN9225DQXAxE9dFrIZzy8MK","gpuType":"T4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}